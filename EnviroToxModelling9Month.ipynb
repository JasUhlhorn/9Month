{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 9 Month Modelling\n",
        "\n",
        "## EnviroTox Database"
      ],
      "metadata": {
        "id": "pbTwDlPE3E8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up"
      ],
      "metadata": {
        "id": "tyl3RufR3CWI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "94f_lNRJQ3tr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "import numpy as np\n",
        "import itertools\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import classification_report, r2_score, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "oeOlE-tZzuht"
      },
      "outputs": [],
      "source": [
        "model_types=['RF','SVM']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "TK5kDs14UMmg"
      },
      "outputs": [],
      "source": [
        "file_train='envtox_single_train.csv' # if connected to drive\n",
        "file_test='envtox_single_test.csv'\n",
        "text_file='log.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "uCJOTqxEbX2X"
      },
      "outputs": [],
      "source": [
        "target= 'classification_binary' # 'classification_binary','classification_ternary', 'Classification','Effect_value_(mgL-1)' (2,3,5,reg)\n",
        "selection=['2d'] # Pub, 2d, 3d\n",
        "grid=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8lSBVYDMd3Yl"
      },
      "outputs": [],
      "source": [
        "with open(text_file, \"w\") as file:\n",
        "    file.write(\"Log file for model performances: \\n\")\n",
        "    file.write(\"Input type: \")\n",
        "    for i in selection:\n",
        "      file.write(i+\" \")\n",
        "    file.write(\"\\nTarget: \")\n",
        "    file.write(target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtRS__ftTsCh"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rb2BZtceTtQh"
      },
      "outputs": [],
      "source": [
        "df_train=pd.read_csv(file_train, index_col=0)\n",
        "df_test=pd.read_csv(file_test, index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3r1H5AoRKIR"
      },
      "source": [
        "### Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "kZrFMwNBVk0Y"
      },
      "outputs": [],
      "source": [
        "if 'single' in file_train:\n",
        "  len_meta=7\n",
        "elif 'combined' in file_train:\n",
        "  len_meta=8\n",
        "len_2d=1444\n",
        "len_3d=431\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "L2QcYLNz8Vjt"
      },
      "outputs": [],
      "source": [
        "def extract_relevant_desc_fp(df, selection, target):\n",
        "  index_list=[]\n",
        "  # meta data\n",
        "  index_list.append([1]) # cid\n",
        "  #target data\n",
        "  index_list.append([df.columns.get_loc(target)])\n",
        "  # input data\n",
        "  for selection_item in selection:\n",
        "    if selection_item=='2d':\n",
        "      index_list.append(range(len_meta, len_meta+len_2d))\n",
        "    if selection_item=='3d':\n",
        "      index_list.append(range(len_meta+len_2d,len_meta+len_2d+len_3d))\n",
        "    else:\n",
        "      index_list.append([df.columns.get_loc(x) for x in df.columns if selection_item in x])\n",
        "  #target_species\n",
        "  if 'combined' in file_train:\n",
        "    index_list.append([-1])\n",
        "  return df.iloc[:,list(itertools.chain.from_iterable(index_list))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "76IHNVCV-n_d"
      },
      "outputs": [],
      "source": [
        "df_train=extract_relevant_desc_fp(df_train, selection, target)\n",
        "df_test=extract_relevant_desc_fp(df_test, selection, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "DFZUEoCciZDG"
      },
      "outputs": [],
      "source": [
        "# drop Nan\n",
        "df_train=df_train.dropna(axis=0) #drop rows with missing values\n",
        "df_test=df_test.dropna(axis=0) #drop rows with missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "h0omPkQ_clw3"
      },
      "outputs": [],
      "source": [
        "def labelencoder(train, test):\n",
        "        le_name_mapping = {'Highly toxic': 3, 'Moderately toxic': 2, 'Nontoxic': 0, 'Slightly toxic': 1, 'Very highly toxic': 4}\n",
        "        train.replace({\"Classification\": le_name_mapping}, inplace=True)\n",
        "        test.replace({\"Classification\": le_name_mapping}, inplace=True)\n",
        "        with open(text_file, \"a\") as file:\n",
        "          file.write(\"\\n\"+str(le_name_mapping))\n",
        "        return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "y2i_tTTac4oo"
      },
      "outputs": [],
      "source": [
        "if target=='Classification':\n",
        "  df_train, df_test=labelencoder(df_train, df_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if target=='Effect_value_(mgL-1)':\n",
        "  df_train['Effect_value_(mgL-1)'] = np.log10(df_train['Effect_value_(mgL-1)'])\n",
        "  df_test['Effect_value_(mgL-1)'] = np.log10(df_test['Effect_value_(mgL-1)'])"
      ],
      "metadata": {
        "id": "8XLfzJ6fyoiK"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if '2d' in selection:\n",
        "  scaler = StandardScaler()\n",
        "  scaler.fit(df_train[df_train.columns[2:len_2d+2]])\n",
        "  df_train[df_train.columns[2:len_2d+2]]=scaler.transform(df_train[df_train.columns[2:len_2d+2]])\n",
        "  df_test[df_test.columns[2:len_2d+2]]=scaler.transform(df_test[df_test.columns[2:len_2d+2]])"
      ],
      "metadata": {
        "id": "Don-6MHbwNkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "bDoIrkUbji32"
      },
      "outputs": [],
      "source": [
        "# remove low/zero variance features\n",
        "def remove_low_variance(input_data, variance_threshold=0.0):\n",
        "  selection = VarianceThreshold(variance_threshold)\n",
        "  selection.fit(input_data)\n",
        "  return input_data[input_data.columns[selection.get_support(indices=True)]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "UTghkWMPkRW-"
      },
      "outputs": [],
      "source": [
        "df_train=remove_low_variance(df_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "W5vMG4fzqgnV"
      },
      "outputs": [],
      "source": [
        "df_test=df_test[df_train.columns]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_correlated_features(df, threshold):\n",
        "    corr_col=set()\n",
        "    feature_corr = df.corr()\n",
        "    for i in range(len(feature_corr.columns)):\n",
        "        for j in range(i):\n",
        "            if abs(feature_corr.iloc[i, j]) > threshold:\n",
        "                col_name = feature_corr.columns[i] \n",
        "                corr_col.add(col_name)\n",
        "    return corr_col"
      ],
      "metadata": {
        "id": "5wCuT9Q7TCZ0"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if '2d' in selection:\n",
        "  if 'single' in file_train:\n",
        "    corr_col = extract_correlated_features(df_train.iloc[:,2:], 0.9)\n",
        "  else:\n",
        "    corr_col = extract_correlated_features(df_train.iloc[:,2:-1], 0.9)\n",
        "  print(len(set(corr_col)))\n",
        "  df_train.drop(corr_col,axis=1, inplace=True)\n",
        "  df_test.drop(corr_col,axis=1, inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osRL-fzgUGLd",
        "outputId": "ab9a7ff3-7870-46a5-db22-33096a5a0d88"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "UAWDrMj-qruF"
      },
      "outputs": [],
      "source": [
        "# log file\n",
        "with open(text_file, \"a\") as file:\n",
        "    file.write(\"\\nData shape; Train: \"+ str(df_train.shape) + \" Test: \"+ str(df_test.shape) + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Report"
      ],
      "metadata": {
        "id": "4VJ9-AIa23Oo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "KaUIzitqcrZD"
      },
      "outputs": [],
      "source": [
        "def report_scores_classification(model, df, name_string):\n",
        "    X= df[df.columns[2:]]\n",
        "    y= df[df.columns[1]]\n",
        "    y_pred=model.predict(X)\n",
        "    class_report = classification_report(y, y_pred)\n",
        "    \n",
        "    with open(text_file, \"a\") as file:\n",
        "      file.write(name_string + \"classification Report:  \\n\" + str(class_report) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def report_scores_reg(model, df, name_string):\n",
        "    X= df[df.columns[2:]]\n",
        "    y= df[df.columns[1]]\n",
        "    y_pred=model.predict(X)\n",
        "    r2=r2_score(y, y_pred)\n",
        "    rms = mean_squared_error(y, y_pred, squared=False)\n",
        "    \n",
        "    with open(text_file, \"a\") as file:\n",
        "      file.write(name_string + \"Regression:  \\nR2: \" + str(r2) +\" RMSE: \"+str(rms) + \"\\n\")"
      ],
      "metadata": {
        "id": "LSGEbCDNz62I"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models and Grid Search"
      ],
      "metadata": {
        "id": "PzKLXAxU24uY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "64Yl0TdLuSHV"
      },
      "outputs": [],
      "source": [
        "def rf_model(X,y):\n",
        "    clf= RandomForestClassifier(random_state=0)\n",
        "    clf.fit(X, y)\n",
        "\n",
        "    return clf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def rf_model_reg(X,y):\n",
        "    reg= RandomForestRegressor(random_state=0)\n",
        "    reg.fit(X, y)\n",
        "\n",
        "    return reg"
      ],
      "metadata": {
        "id": "qnjEri7Vy_Ha"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "0Ca3FU0qsvSm"
      },
      "outputs": [],
      "source": [
        "def rf_model_grid_search(df):\n",
        "    X= df[df.columns[2:]]\n",
        "    y= df[df.columns[1]]\n",
        "\n",
        "    # Number of trees in random forest\n",
        "    n_estimators = [int(x) for x in np.linspace(start=10, stop=2000, num=3)]\n",
        "    # Number of features to consider at every split\n",
        "    max_features = ['log2', 'sqrt']\n",
        "    # Maximum number of levels in tree\n",
        "    max_depth = [int(x) for x in np.linspace(1, 110, num=2)]\n",
        "    max_depth.append(None)\n",
        "    # Minimum number of samples required to split a node\n",
        "    min_samples_split = [2, 5, 10]\n",
        "    # Minimum number of samples required at each leaf node\n",
        "    min_samples_leaf = [1, 2, 4]\n",
        "    # Method of selecting samples for training each tree\n",
        "    bootstrap = [True, False]\n",
        "\n",
        "    param_grid = {'n_estimators': n_estimators,\n",
        "                   'max_features': max_features,\n",
        "                   'max_depth': max_depth,\n",
        "                   'min_samples_split': min_samples_split,\n",
        "                   'min_samples_leaf': min_samples_leaf,\n",
        "                   'bootstrap': bootstrap}\n",
        "\n",
        "\n",
        "    rfc = RandomForestClassifier(random_state=0)\n",
        "    CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv=5)\n",
        "    CV_rfc.fit(X, y)\n",
        "\n",
        "    with open(text_file, \"a\") as file:\n",
        "      file.write(\"Best parameters:\" + str(CV_rfc.best_params_) + \"\\n\")\n",
        "      file.write(\"Score:\" + str(CV_rfc.best_score_) + \"\\n\")\n",
        "      \n",
        "    # use best parameter setting\n",
        "    model=rf_model(CV_rfc.best_params_, X,y)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "uSEBqq75dpwc"
      },
      "outputs": [],
      "source": [
        "def svm_model(X,y):\n",
        "    clf= svm.SVC(random_state=0)\n",
        "    clf.fit(X, y)\n",
        "    return clf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def svm_model_reg(X,y):\n",
        "    np.random.seed(42)\n",
        "    reg= svm.SVR()\n",
        "    reg.fit(X, y)\n",
        "    return reg"
      ],
      "metadata": {
        "id": "gkQHGsowzR0T"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "kZktsKNfFeuo"
      },
      "outputs": [],
      "source": [
        "def svm_model_grid_search(df):\n",
        "    X= df[df.columns[2:]]\n",
        "    y= df[df.columns[1]]\n",
        "    param_grid = [{\"kernel\": [\"rbf\"], \"gamma\": [1e-3, 1e-4, 'auto', 'scale'], \"C\": [0.5, 1, 25, 250]}, #separate as gamma only relevant for rbf kernel\n",
        "                  {\"kernel\": [\"linear\"], \"C\": [0.5, 1, 25, 250]}]\n",
        "\n",
        "\n",
        "    svc = svm.SVC(random_state=0)\n",
        "    CV_svc = GridSearchCV(estimator=svc, param_grid=param_grid, cv=5)\n",
        "    CV_svc.fit(X, y)\n",
        "\n",
        "    with open(text_file, \"a\") as file:\n",
        "      file.write(\"Best parameters:\" + str(CV_svc.best_params_) + \"\\n\")\n",
        "      file.write(\"Score:\" + str(CV_svc.best_score_) + \"\\n\")\n",
        "\n",
        "    # use best parameter setting\n",
        "    model= svm_model(CV_svc.best_params_, X,y)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "_7hJdD2E282J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJwohiCkwNw-",
        "outputId": "3aed84f9-fa2c-4b7b-f815-c7b9a28678e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random forest\n",
            "Support vector machine\n"
          ]
        }
      ],
      "source": [
        "if grid==False:\n",
        "  X= df_train[df_train.columns[2:]]\n",
        "  y= df_train[df_train.columns[1]]\n",
        "  if 'RF' in model_types:\n",
        "    print('Random forest')\n",
        "    with open(text_file, \"a\") as file:\n",
        "      file.write(\"Random forest model\\n\")\n",
        "    if target=='Effect_value_(mgL-1)':\n",
        "      model=rf_model_reg(X,y)\n",
        "      report_scores_reg(model,df_train,  'Train')\n",
        "      report_scores_reg(model, df_test,'Test')\n",
        "    else:\n",
        "      model=rf_model(X,y)\n",
        "      report_scores_classification(model,df_train,  'Train')\n",
        "      report_scores_classification(model, df_test,'Test')\n",
        "  if 'SVM' in model_types:\n",
        "    print('Support vector machine')\n",
        "    with open(text_file, \"a\") as file:\n",
        "      file.write(\"Support vector machine\\n\")\n",
        "    if target=='Effect_value_(mgL-1)':\n",
        "      model=svm_model_reg(X,y)\n",
        "      report_scores_reg(model,df_train,  'Train')\n",
        "      report_scores_reg(model, df_test,'Test')\n",
        "    else:\n",
        "      model=svm_model(X,y)\n",
        "      report_scores_classification(model,df_train,  'Train')\n",
        "      report_scores_classification(model,df_test,  'Test')\n",
        "else:\n",
        "  if 'RF' in model_types:\n",
        "    print('Random forest')\n",
        "    with open(text_file, \"a\") as file:\n",
        "      file.write(\"Random forest model\\n\")\n",
        "    model=rf_model_grid_search(df_train)\n",
        "    report_scores_classification(model,df_train,  'Train')\n",
        "    report_scores_classification(model, df_test,'Test')\n",
        "  if 'SVM' in model_types:\n",
        "    print('Support vector machine')\n",
        "    with open(text_file, \"a\") as file:\n",
        "      file.write(\"Support vector machine\\n\")\n",
        "    model=svm_model_grid_search(df_train)\n",
        "    report_scores_classification(model,df_train,  'Train')\n",
        "    report_scores_classification(model,df_test,  'Test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "8qy_Umjfknpt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "22fcbeb8-3290-4375-8987-2f499cbbf90b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_233cc51e-fd1c-4bf4-bcb2-bcb9f174f768\", \"log.txt\", 1596)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download('log.txt')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "EnviroToxModelling9Month.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}